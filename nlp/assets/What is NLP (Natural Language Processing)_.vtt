WEBVTT

00:00:00.480 --> 00:00:06.720
What is natural language processing? Well, 
you're doing it right now, you're listening  

00:00:06.720 --> 00:00:13.040
to the words and the sentences that I'm forming 
and you are forming some sort of comprehension  

00:00:13.040 --> 00:00:20.240
from it. And when we ask a computer to do that 
that is NLP, or natural language processing.  

00:00:21.280 --> 00:00:24.880
My name is Martin Keen, I'm 
a Master Inventor at IBM,  

00:00:24.880 --> 00:00:32.240
and I've utilized NLP in a good number of 
my invention disclosures. NLP really has a  

00:00:32.240 --> 00:00:40.800
really high utility value in all sorts of AI 
applications. Now NLP starts with something called  

00:00:40.800 --> 00:00:47.600
unstructured text. What is that? Well, that's 
just what you and I say, that's how we speak.  

00:00:47.600 --> 00:00:57.840
So, for example, some unstructured text is 
"add eggs and milk to my shopping list."  

00:00:59.040 --> 00:01:07.680
Now you and I understand exactly what that means, 
but it is unstructured at least to a computer.

00:01:11.760 --> 00:01:17.200
So what we need to do, is to have a structured 
representation of that same information that  

00:01:17.200 --> 00:01:22.240
a computer can process. Now that might look 
something a bit more like this where we have a  

00:01:22.880 --> 00:01:31.200
shopping list element. And then it has sub 
elements within it like an item for eggs,

00:01:34.080 --> 00:01:39.840
and an item for milk.

00:01:43.120 --> 00:01:45.760
That is an example of 
something that is structured.

00:01:50.000 --> 00:01:56.240
Now the job of natural language processing 
is to translate between these two things.  

00:01:56.240 --> 00:02:03.840
So NLP sits right in the middle here translating 
between unstructured and structured data. And when  

00:02:03.840 --> 00:02:11.200
we go from structure from unstructured here 
to structured this way, that's called NLU, or  

00:02:11.200 --> 00:02:16.960
natural language understanding. And when we 
go this way from structured to unstructured,  

00:02:16.960 --> 00:02:24.400
that's called natural language generation, 
or NLG. We're going to focus today primarily  

00:02:24.400 --> 00:02:30.320
on going from unstructured to structured in 
natural language processing now let's think of  

00:02:30.320 --> 00:02:39.680
some use cases where nlp might be quite handy. 
First of all, we've got machine translation.

00:02:41.840 --> 00:02:52.720
Now when we translate from one language to 
another we need to understand the context of  

00:02:52.720 --> 00:02:57.840
that sentence. It's not just a case of taking 
each individual word from say English and  

00:02:57.840 --> 00:03:02.560
then translating it into another language. We 
need to understand the overall structure  

00:03:02.560 --> 00:03:08.480
and context of what's being said. And my 
favorite example of this going horribly wrong  

00:03:08.480 --> 00:03:15.040
is if you take the phrase the "spirit is willing, 
but the flesh is weak" and you translate that from  

00:03:15.040 --> 00:03:20.400
English to Russian and then you translate 
that Russian translation back into English  

00:03:20.400 --> 00:03:26.080
you're going to go from the "spirit is willing, 
but the flesh is weak" to something a bit more  

00:03:26.080 --> 00:03:32.000
like the "vodka is good, but the meat is 
rotten" which is really not the intended  

00:03:32.000 --> 00:03:39.040
context of that sentence whatsoever. So 
NLP can help with situations like that. Now  

00:03:39.040 --> 00:03:46.080
the the second kind of use case that I like 
to mention relates to virtual assistants,  

00:03:46.080 --> 00:03:53.040
and also to things like chatbots. Now a virtual 
assistant that's something like Siri, or Alexa  

00:03:53.040 --> 00:04:01.120
on your phone that is taking human utterances and 
deriving a command to execute based upon that. And  

00:04:01.120 --> 00:04:07.360
a chatbot is something similar except in written 
language and that's taking written language and  

00:04:07.360 --> 00:04:13.840
then using it to traverse a decision tree in order 
to take an action. NLP is very helpful there.  

00:04:14.480 --> 00:04:24.800
Another use case is for sentiment analysis. Now 
this is taking some text perhaps an email message  

00:04:24.800 --> 00:04:30.400
or a product review and trying to derive 
the sentiment that's expressed within it.  

00:04:30.400 --> 00:04:38.400
So for example, is this product review a positive 
sentiment or a negative sentiment, is it written  

00:04:38.960 --> 00:04:46.800
as a serious statement or is it being sarcastic? 
We can use NLP to tell us. And then finally,  

00:04:47.600 --> 00:04:54.480
another good example is spam detection so this 
is a case of looking at a given email message  

00:04:54.480 --> 00:04:59.200
and trying to drive is this a real email 
message or is it spam and we can look for  

00:04:59.200 --> 00:05:06.480
pointers within the content of the message. So 
things like overused words or poor grammar or an  

00:05:06.480 --> 00:05:13.600
inappropriate claim of urgency can all indicate 
that this is actually perhaps spam. So those are  

00:05:13.600 --> 00:05:20.880
some of the things that NLP can provide but how 
does it work well the thing with NLP is it's

00:05:20.880 --> 00:05:28.800
not like one algorithm, it's actually more like a 
bag of tools and you can apply these bag of tools  

00:05:28.800 --> 00:05:36.640
to be able to resolve some of these use cases. 
Now the input to NLP is some unstructured text  

00:05:36.640 --> 00:05:43.040
so either some written text or spoken text that 
has been converted to written text through a  

00:05:43.040 --> 00:05:51.840
speech to text algorithm. Once we've got that, 
the first stage of NLP is called tokenization

00:05:54.880 --> 00:06:02.240
This is about taking a string and breaking 
it down into chunks so if we consider the  

00:06:02.240 --> 00:06:08.000
unstructured text we've got here "add 
eggs and milk to my shopping list"  

00:06:08.640 --> 00:06:11.760
that's eight words that can be eight tokens.  

00:06:11.760 --> 00:06:18.800
And from here on in we are going to work one 
token at a time as we traverse through this. Now  

00:06:18.800 --> 00:06:24.720
the first stage once we've got things down into 
tokens that we can perform is called stemming.

00:06:27.360 --> 00:06:34.160
And this is all about deriving the word stem 
for a given token. So for example, running,  

00:06:34.160 --> 00:06:40.880
runs, and ran, the word stem for all three of 
those is run. We're just kind of removing the  

00:06:40.880 --> 00:06:45.120
prefix and the suffixes and normalizing the 
tense and we're getting to the word stem.  

00:06:46.080 --> 00:06:53.520
But stemming doesn't work well for every 
token. For example, universal and university,  

00:06:54.560 --> 00:06:59.520
well they don't really stem down to 
universe. For situations like that,  

00:06:59.520 --> 00:07:06.240
there is another tool that we have 
available and that is called lemmatization.  

00:07:08.240 --> 00:07:14.960
And lemmatization takes a given token and learns 
its meaning through a dictionary definition  

00:07:14.960 --> 00:07:24.160
and from there it can derive its root, or its lem. 
So take better for example, better is derived from  

00:07:24.160 --> 00:07:34.480
good so the root, or the lem, of better is good. 
The stem of better would be bet. So you can see  

00:07:34.480 --> 00:07:41.200
that it is significant whether we use stemming, 
or we use lemmatization for a given token.  

00:07:42.880 --> 00:07:49.200
Now next thing we can do is we can do a 
process called part of speech tagging.

00:07:51.440 --> 00:07:57.840
And what this is doing is for a given token 
it's looking where that token is used within the  

00:07:57.840 --> 00:08:09.600
context of a sentence. So take the word make for 
example, if I say "I'm going to make dinner", make  

00:08:09.600 --> 00:08:16.960
is a verb. But if I ask you "what make is your 
laptop?", well make is now a noun. So where that  

00:08:16.960 --> 00:08:21.840
token is used in the sentence matters, part of 
speech tagging can help us derive that context.  

00:08:22.400 --> 00:08:28.480
And then finally, another stage 
is named entity recognition.  

00:08:30.000 --> 00:08:36.480
And what this is asking is for a given token 
is there an entity associated with it. So  

00:08:36.480 --> 00:08:45.520
for example, a token of Arizona has an entity of a 
U.S. state whereas a token of Ralph has an entity  

00:08:45.520 --> 00:08:52.480
of a person's name. And these are some of the 
tools that we can apply in this big bag of tools  

00:08:52.480 --> 00:08:58.800
that we have for NLP in order to get from this 
unstructured human speech through to something  

00:08:58.800 --> 00:09:04.480
structured that a computer can understand. And 
once we've done that then we can apply that  

00:09:04.480 --> 00:09:11.120
structured data to all sorts of AI applications. 
Now there's obviously a lot more to it than this  

00:09:11.120 --> 00:09:15.920
and I've included some links in the description if 
you'd like to know more, but hopefully this made  

00:09:16.480 --> 00:09:24.960
some sense and that you were able to process some 
of the natural language that I've shared today.  

00:09:25.920 --> 00:09:31.840
Thanks for watching. If you have questions, 
please drop us a line below. And if you want  

00:09:31.840 --> 00:09:35.840
to see more videos like this in the 
future, please like and subscribe.

